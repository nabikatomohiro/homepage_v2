{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "33e6d903-c2af-4bb0-c189-f2cee098c564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Google Colaboratory環境を検出しました\n",
            "\n",
            "📦 必要なライブラリをインストール中...\n",
            "✅ ライブラリのインストール完了\n",
            "\n",
            "📥 リポジトリをクローン中: https://github.com/lasa-or-jp/la-bench.git\n",
            "✅ リポジトリのクローン完了: la-bench/\n",
            "\n",
            "📍 作業ディレクトリ: /content/la-bench/la-bench\n",
            "\n",
            "📊 プロジェクト構造:\n",
            "total 416\n",
            "drwxr-xr-x 8 root root   4096 Oct 21 08:33 .\n",
            "drwxr-xr-x 9 root root   4096 Oct 21 08:33 ..\n",
            "-rw-r--r-- 1 root root   4741 Oct 21 08:33 CLAUDE.md\n",
            "drwxr-xr-x 4 root root   4096 Oct 21 08:33 code\n",
            "-rw-r--r-- 1 root root   2658 Oct 21 08:33 CONTRIBUTING.md\n",
            "drwxr-xr-x 4 root root   4096 Oct 21 08:33 data\n",
            "drwxr-xr-x 3 root root   4096 Oct 21 08:33 docs\n",
            "drwxr-xr-x 8 root root   4096 Oct 21 08:33 .git\n",
            "drwxr-xr-x 3 root root   4096 Oct 21 08:33 .github\n",
            "-rw-r--r-- 1 root root    979 Oct 21 08:33 .gitignore\n",
            "-rw-r--r-- 1 root root   1101 Oct 21 08:33 LICENSE\n",
            "drwxr-xr-x 2 root root   4096 Oct 21 08:33 notebooks\n",
            "-rw-r--r-- 1 root root    569 Oct 21 08:33 pyproject.toml\n",
            "-rw-r--r-- 1 root root  12425 Oct 21 08:33 README.md\n",
            "-rw-r--r-- 1 root root    121 Oct 21 08:33 requirements.txt\n",
            "-rw-r--r-- 1 root root 346546 Oct 21 08:33 uv.lock\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: 環境設定とセットアップ\n",
        "\"\"\"\n",
        "LA-Bench 2025: 実験手順生成タスク\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. 環境セットアップ { display-mode: \"form\" }\n",
        "#@markdown このセルを実行して必要なライブラリをインストールし、リポジトリをクローンします。\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Colabかどうかの確認\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Google Colaboratory環境を検出しました\")\n",
        "    # 必要なライブラリのインストール\n",
        "    print(\"\\n📦 必要なライブラリをインストール中...\")\n",
        "    !pip install -q openai pyyaml tqdm pandas\n",
        "\n",
        "    print(\"✅ ライブラリのインストール完了\")\n",
        "\n",
        "    # GitHubリポジトリのクローン\n",
        "    REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "    REPO_NAME = \"la-bench\"\n",
        "\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"\\n📥 リポジトリをクローン中: {REPO_URL}\")\n",
        "        !git clone -q {REPO_URL}\n",
        "        print(f\"✅ リポジトリのクローン完了: {REPO_NAME}/\")\n",
        "    else:\n",
        "        print(f\"\\n📂 リポジトリは既に存在します: {REPO_NAME}/\")\n",
        "        print(\"📥 最新版に更新中...\")\n",
        "        !cd {REPO_NAME} && git pull -q\n",
        "        print(\"✅ 更新完了\")\n",
        "\n",
        "    # 作業ディレクトリの設定\n",
        "    WORK_DIR = Path(REPO_NAME)\n",
        "    os.chdir(WORK_DIR)\n",
        "    print(f\"\\n📍 作業ディレクトリ: {os.getcwd()}\")\n",
        "\n",
        "    # ディレクトリ構造の確認\n",
        "    print(\"\\n📊 プロジェクト構造:\")\n",
        "    !ls -la\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"⚠️ ローカル環境で実行中です\")\n",
        "    if Path.cwd().name == \"notebooks\":\n",
        "        os.chdir(Path.cwd().parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PZr_6rXsyqlK",
        "outputId": "d0e409d7-815e-437d-936b-93c2f18cd844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔑 OpenAI API Keyを入力: ··········\n",
            "✅ APIキーが設定されました\n",
            "🔑 APIキー: ********************WTEA\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: OpenAI APIキーの設定\n",
        "#@title 2. OpenAI API Key設定 { display-mode: \"form\" }\n",
        "#@markdown OpenAI APIキーを入力してください。キーは安全に管理されます。\n",
        "\n",
        "\n",
        "# APIキーの取得方法を選択\n",
        "use_secrets = False  #@param {type:\"boolean\"}\n",
        "#@markdown ☝️ Google Colab Secretsを使用する場合はチェック\n",
        "\n",
        "if IN_COLAB:\n",
        "    import getpass\n",
        "    from google.colab import userdata\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secretsから取得\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"✅ APIキーをSecretsから取得しました\")\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Secretsからの取得に失敗しました\")\n",
        "            print(\"左側のパネルの🔑アイコンから'OPENAI_API_KEY'を設定してください\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # 直接入力\n",
        "        api_key_input = getpass.getpass(\"🔑 OpenAI API Keyを入力: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"✅ APIキーが設定されました\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"⚠️ APIキーが設定されていません（ヒューリスティック手法のみ使用）\")\n",
        "else:\n",
        "    # ローカル環境の場合\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# APIキーの検証\n",
        "if API_KEY:\n",
        "    print(f\"🔑 APIキー: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"⚠️ GPT機能は使用できません\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "71dPwmdnzEfP",
        "outputId": "0bb3055c-0834-4568-ee80-2cadbdacee77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "実行環境: Google Colab\n",
            "実行時刻: 2025-10-21 08:34:49\n",
            "OpenAI利用可能: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: ライブラリのインポートと設定\n",
        "#@title 3. ライブラリのインポート { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Set, Any\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# データ処理\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"⚠️ OpenAIライブラリが利用できません\")\n",
        "\n",
        "# プログレスバー (Colab対応)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ログ設定\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"実行環境: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"実行時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAI利用可能: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0rypmgB20Yc2"
      },
      "outputs": [],
      "source": [
        "# Cell 4: データ構造\n",
        "#@title 4. データ構造の定義 { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ReferenceEntry:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ExampleInput:\n",
        "    instruction: str\n",
        "    mandatory_objects: Set[str] = field(default_factory=set)\n",
        "    source_protocol_steps: List[Step] = field(default_factory=list)\n",
        "    expected_final_states: Set[str] = field(default_factory=set)\n",
        "    references: List[ReferenceEntry] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ExampleOutput:\n",
        "    procedure_steps: List[Step] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class Measurement:\n",
        "    specific_criteria: Dict[str, int] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExampleSample:\n",
        "    id: str\n",
        "    input: ExampleInput\n",
        "    output: ExampleOutput\n",
        "    measurement: Optional[Measurement] = None\n",
        "\n",
        "def _to_set(x):\n",
        "    return set(x) if isinstance(x, (list, set, tuple)) else set()\n",
        "\n",
        "def _to_list(x):\n",
        "    return list(x) if isinstance(x, (list, set, tuple)) else (x if isinstance(x, list) else [])\n",
        "\n",
        "def _to_steps(x) -> List[Step]:\n",
        "    steps: List[Step] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return steps\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                sid = int(it.get(\"id\", len(steps) + 1))\n",
        "            except Exception:\n",
        "                sid = len(steps) + 1\n",
        "            steps.append(Step(id=sid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, s in enumerate(arr, start=1):\n",
        "            steps.append(Step(id=idx, text=str(s).strip()))\n",
        "    return steps\n",
        "\n",
        "def _to_references(x) -> List[ReferenceEntry]:\n",
        "    refs: List[ReferenceEntry] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return refs\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                rid = int(it.get(\"id\", len(refs) + 1))\n",
        "            except Exception:\n",
        "                rid = len(refs) + 1\n",
        "            refs.append(ReferenceEntry(id=rid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, ref in enumerate(arr, start=1):\n",
        "            refs.append(ReferenceEntry(id=idx, text=str(ref).strip()))\n",
        "    return refs\n",
        "\n",
        "def parse_sample(obj: Dict[str, Any]) -> ExampleSample:\n",
        "    sid = obj.get(\"id\") or obj.get(\"sample_id\") or \"unknown\"\n",
        "    i = obj.get(\"input\", {})\n",
        "    o = obj.get(\"output\", {})\n",
        "    m = obj.get(\"measurement\", {})\n",
        "\n",
        "    # Measurement.specific_criteria を dict に正規化（list形式も許容）\n",
        "    sc_raw = m.get(\"specific_criteria\", {})\n",
        "    sc: Dict[str, int] = {}\n",
        "    if isinstance(sc_raw, dict):\n",
        "        for k, v in sc_raw.items():\n",
        "            try:\n",
        "                sc[str(k)] = int(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "    elif isinstance(sc_raw, list):\n",
        "        for it in sc_raw:\n",
        "            try:\n",
        "                k = it.get(\"item\")\n",
        "                v = int(it.get(\"score\", 0))\n",
        "                if k:\n",
        "                    sc[str(k)] = v\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    sample = ExampleSample(\n",
        "        id=str(sid),\n",
        "        input=ExampleInput(\n",
        "            instruction=str(i.get(\"instruction\", \"\")).strip(),\n",
        "            mandatory_objects=_to_set(i.get(\"mandatory_objects\", [])),\n",
        "            source_protocol_steps=_to_steps(i.get(\"source_protocol_steps\", [])),\n",
        "            expected_final_states=_to_set(i.get(\"expected_final_states\", [])),\n",
        "            references=_to_references(i.get(\"references\", [])),\n",
        "        ),\n",
        "        output=ExampleOutput(\n",
        "            procedure_steps=_to_steps(o.get(\"procedure_steps\", []))\n",
        "        ),\n",
        "        measurement=Measurement(specific_criteria=sc) if sc else None\n",
        "    )\n",
        "    return sample\n",
        "\n",
        "def load_example_jsonl(path: str):\n",
        "    samples = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"JSONL not found: {p}\")\n",
        "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ JSONL parse error: {e}\")\n",
        "            continue\n",
        "        samples.append(parse_sample(obj))\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MXF0Ou0B6sFB",
        "outputId": "70e4b615-9237-4ee5-f44b-92707b8ecc9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 5 samples from data/example/example.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: JSONLローダーの利用\n",
        "#@title 5. JSONLファイルを読み込む { display-mode: \"form\" }\n",
        "#@markdown exampleを使うとき：`data/example/example.jsonl`\n",
        "#@markdown public_testを使うとき：`data/public_test/public_test.jsonl`\n",
        "\n",
        "jsonl_path = 'data/example/example.jsonl'  #@param {type:'string'}\n",
        "\n",
        "try:\n",
        "    samples = load_example_jsonl(jsonl_path)\n",
        "    print(f'✅ Loaded {len(samples)} samples from {jsonl_path}')\n",
        "except Exception as e:\n",
        "    print(f'❌ Load error: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WZ94EpzOInJr",
        "outputId": "fe2bbf99-5ff4-498f-cfc0-7dbf906e9bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 生成完了: 5 samples\n",
            "例: sample_1 → 11 steps\n",
            "📄 Saved JSONL: outputs/runs/generated_20251021_083608.jsonl\n",
            "Download file: outputs/runs/generated_20251021_083608.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49901164-4f8b-4fad-b002-7e45b6127e0e\", \"generated_20251021_083608.jsonl\", 12968)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell 6: 実験手順の生成（OpenAI, Pydantic構造化）\n",
        "#@title 6. LLMで Input から Output（procedure_steps）を生成 { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# モデル設定\n",
        "MODEL_NAME = \"gpt-4.1-mini-2025-04-14\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "#@markdown gpt-4o-mini, gpt-4o-2024-08-06, あるいはそれ以降のモデルに対応しています。<br>\n",
        "#@markdown (Structured outputを使用しているため) <br>\n",
        "#@markdown gpt-5系モデルを使用する場合、temperature=1.0としてください。\n",
        "TEMPERATURE = 0.7 # @param\n",
        "\n",
        "#@markdown `build_messages`関数において、LLMの入力を設計しています。\n",
        "\n",
        "class StepModel(BaseModel):\n",
        "    id: int = Field(ge=1, description=\"ステップ番号\")\n",
        "    text: str = Field(description=\"実験手順の詳細な説明\")\n",
        "\n",
        "class GeneratedOutput(BaseModel):\n",
        "    procedure_steps: List[StepModel] = Field(\n",
        "        description=\"実験手順のリスト\",\n",
        "        min_items=1,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "def build_messages(sample: ExampleSample) -> list[dict]:\n",
        "    sys = (\n",
        "        \"あなたは生命科学実験の専門家です。以下の Input を読み、\"\n",
        "        \"日本語で実行可能な実験手順（procedure_steps）を返してください。\"\n",
        "        \"制約: ステップ数は最大50、各ステップは10文以下、idは1から昇順。\"\n",
        "    )\n",
        "    user_lines = []\n",
        "    user_lines.append(f\"【実験指示】\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        user_lines.append(\"\\n【使用する物品】\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            user_lines.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        user_lines.append(\"\\n【元プロトコルの手順（参考）】\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            user_lines.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        user_lines.append(\"\\n【期待される最終状態】\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            user_lines.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        user_lines.append(\"\\n【参考文献】\")\n",
        "        for ref in sample.input.references:\n",
        "            user_lines.append(f\"- [{ref.id}] {ref.text}\")\n",
        "    usr = \"\\n\".join(user_lines)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": usr},\n",
        "    ]\n",
        "\n",
        "def generate_outputs(samples: list[ExampleSample]) -> list[dict]:\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    results: list[dict] = []\n",
        "    for sm in samples:\n",
        "        msgs = build_messages(sm)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=MODEL_NAME,\n",
        "                messages=msgs,\n",
        "                temperature=TEMPERATURE,\n",
        "                response_format=GeneratedOutput,\n",
        "            )\n",
        "            parsed: GeneratedOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            steps = [\n",
        "                Step(id=s.id, text=s.text)\n",
        "                for s in sorted(parsed.procedure_steps, key=lambda x: x.id)\n",
        "            ][:50]\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 生成失敗: {sm.id}: {e}\")\n",
        "            steps = []  # no fallback\n",
        "        results.append({\n",
        "            \"id\": sm.id,\n",
        "            \"procedure_steps\": [{\"id\": s.id, \"text\": s.text} for s in steps],\n",
        "        })\n",
        "    print(f\"✅ 生成完了: {len(results)} samples\")\n",
        "    return results\n",
        "\n",
        "# 実行\n",
        "generated_results = generate_outputs(samples)\n",
        "if generated_results:\n",
        "    print(f\"例: {generated_results[0]['id']} → {len(generated_results[0]['procedure_steps'])} steps\")\n",
        "\n",
        "# 生成結果を JSONL で保存し、ダウンロードリンクを表示\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "out_dir = Path('./outputs/runs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "jsonl_path = out_dir / f'generated_{ts}.jsonl'\n",
        "with jsonl_path.open('w', encoding='utf-8') as f:\n",
        "    for rec in generated_results:\n",
        "        obj = {\"id\": rec[\"id\"], \"output\": {\"procedure_steps\": rec[\"procedure_steps\"]}}\n",
        "        line = json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"📄 Saved JSONL: {jsonl_path}\")\n",
        "\n",
        "# ダウンロード（Colab/ローカル双方に対応）\n",
        "try:\n",
        "    from google.colab import files as colab_files  # type: ignore\n",
        "    # ダウンロード確認ダイアログを出して、yならダウンロード\n",
        "    from google.colab.output import eval_js\n",
        "    print(f\"Download file: {jsonl_path}\")\n",
        "    confirm = eval_js('confirm(\"生成されたJSONLファイルをダウンロードしますか？\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(jsonl_path))\n",
        "    else:\n",
        "      print(\"ダウンロードをスキップしました。\")\n",
        "\n",
        "except Exception:\n",
        "    from IPython.display import FileLink, display\n",
        "    display(FileLink(str(jsonl_path.resolve())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wYtMf3bJOzcN",
        "outputId": "571c0af2-c127-470c-f479-a01a6bf5b612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ LLM-as-a-judge: Scored 5 samples (0-10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         id  general_score  specific_score  total_score\n",
              "0  sample_1            5.0             3.0          8.0\n",
              "1  sample_2            5.0             3.0          8.0\n",
              "2  sample_3            5.0             3.0          8.0\n",
              "3  sample_4            5.0             2.0          7.0\n",
              "4  sample_5            5.0             3.0          8.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>general_score</th>\n",
              "      <th>specific_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sample_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4743e574-c900-4522-9fc4-87cd325857b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4743e574-c900-4522-9fc4-87cd325857b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4743e574-c900-4522-9fc4-87cd325857b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(FileLink(str(csv_path\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"sample_2\",\n          \"sample_5\",\n          \"sample_3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specific_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 2.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 7.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📄 Saved: outputs/runs/eval_llm_20251021_083608.csv\n",
            "Download file: outputs/runs/eval_llm_20251021_083608.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0950a69f-f73b-451a-862a-12c36180c242\", \"eval_llm_20251021_083608.csv\", 1204)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell 7: LLM-as-a-judge 評価（10点満点）\n",
        "#@title 7. LLM で共通5点 + 個別5点を採点 { display-mode: \"form\" }\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"OpenAI SDK v1 が見つかりません。`uv add openai` で追加してください。\") from e\n",
        "\n",
        "JUDGE_MODEL = \"gpt-4.1-mini\"  # 高性能推奨モデルに変更可\n",
        "JUDGE_TEMPERATURE = 0.2\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    general_score: float = Field(ge=0, le=5)\n",
        "    specific_score: float = Field(ge=0, le=5)\n",
        "    final_score: float = Field(ge=0, le=10)\n",
        "    general_reason: str\n",
        "    specific_matches: List[str] = []\n",
        "    notes: Optional[str] = None\n",
        "\n",
        "def build_judge_messages(sample: ExampleSample, steps: List[Step]) -> list[dict]:\n",
        "    # 評価基準（共通5点 + 個別5点）\n",
        "    system = (\n",
        "        \"あなたは生命科学実験の専門家であり、公平な採点者です。\"\n",
        "        \"以下の基準に従って、与えられた Input と生成手順（Output）を評価し、\"\n",
        "        \"general_score(0-5) と specific_score(0-5) と final_score(0-10) を出力してください。\"\n",
        "        \"\\n\\n[共通採点基準 5点満点]\\n\"\n",
        "        \"加点(+1ずつ): 1) 実験指示のパラメータ反映, 2) 使用する物品の反映, 3) 元手順の論理反映, 4) 期待される最終状態の達成, 5) 適切な補完。\\n\"\n",
        "        \"減点: 不自然な日本語/ハルシネーション, 計算ミス, 手順矛盾。\\n\"\n",
        "        \"上限: 入力手順の丸写し等の過度の安全性が見られる場合、general_score は最大2点に制限。\\n\\n\"\n",
        "        \"[個別採点基準 5点満点]\\n\"\n",
        "        \"与えられた specific_criteria の各 item が手順に含まれる/満たすなら、その score を加点（合計5点で上限）。\"\n",
        "    )\n",
        "\n",
        "    parts = []\n",
        "    parts.append(f\"【実験指示】\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        parts.append(\"\\n【使用する物品】\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            parts.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        parts.append(\"\\n【元プロトコルの手順（参考）】\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            parts.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        parts.append(\"\\n【期待される最終状態】\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            parts.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        parts.append(\"\\n【参考文献】\")\n",
        "        for ref in sample.input.references:\n",
        "            parts.append(f\"- [{ref.id}] {ref.text}\")\n",
        "\n",
        "    parts.append(\"\\n【生成手順（Output）】\")\n",
        "    for s in steps:\n",
        "        parts.append(f\"- {s.id}. {s.text}\")\n",
        "\n",
        "    parts.append(\"\\n【specific_criteria】\")\n",
        "    if sample.measurement and sample.measurement.specific_criteria:\n",
        "        for item, sc in sample.measurement.specific_criteria.items():\n",
        "            parts.append(f\"- ({int(sc)}点) {item}\")\n",
        "    else:\n",
        "        parts.append(\"- なし\")\n",
        "\n",
        "    user = \"\\n\".join(parts)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "def judge_with_llm(samples: List[ExampleSample], generated: list[dict]) -> pd.DataFrame:\n",
        "    client = OpenAI(api_key=API_KEY) if 'API_KEY' in globals() and API_KEY else OpenAI()\n",
        "    proc_map = {g['id']: [Step(id=it['id'], text=it['text']) for it in g['procedure_steps']] for g in generated}\n",
        "    rows = []\n",
        "    quota_exhausted = False\n",
        "    def _is_insufficient_quota(err: Exception) -> bool:\n",
        "        s = str(err)\n",
        "        return 'insufficient_quota' in s or 'You exceeded your current quota' in s\n",
        "    for sm in samples:\n",
        "        if quota_exhausted:\n",
        "            print(f\"⏭️ スキップ採点: {sm.id}（クォータ不足）\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_due_to_quota',\n",
        "            })\n",
        "            continue\n",
        "        steps = proc_map.get(sm.id, [])\n",
        "        msgs = build_judge_messages(sm, steps)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=msgs,\n",
        "                temperature=JUDGE_TEMPERATURE,\n",
        "                response_format=JudgeOutput,\n",
        "            )\n",
        "            parsed: JudgeOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': parsed.general_score,\n",
        "                'specific_score': parsed.specific_score,\n",
        "                'total_score': parsed.final_score,\n",
        "                'notes': parsed.notes or '',\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 評価失敗: {sm.id}: {e}\")\n",
        "            if _is_insufficient_quota(e):\n",
        "                print(\"⚠️ APIクォータ不足のため、以降の採点を中断します。プラン/課金設定をご確認ください。\")\n",
        "                quota_exhausted = True\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'evaluation_failed',\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# 実行\n",
        "df = judge_with_llm(samples, generated_results)\n",
        "print(f\"✅ LLM-as-a-judge: Scored {len(df)} samples (0-10)\")\n",
        "try:\n",
        "    display(df[['id','general_score','specific_score','total_score']])\n",
        "except Exception:\n",
        "    print(df[['id','general_score','specific_score','total_score']])\n",
        "\n",
        "csv_path = out_dir / f'eval_llm_{ts}.csv'\n",
        "df.to_csv(csv_path, index=False, encoding=\"utf_8_sig\")\n",
        "print(f'📄 Saved: {csv_path}')\n",
        "\n",
        "try:\n",
        "    # ダウンロード確認ダイアログを出して、yならダウンロード\n",
        "    print(f\"Download file: {csv_path}\")\n",
        "    confirm = eval_js('confirm(\"生成されたCSVファイルをダウンロードしますか？\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(csv_path))\n",
        "    else:\n",
        "      print(\"ダウンロードをスキップしました。\")\n",
        "\n",
        "except Exception:\n",
        "    display(FileLink(str(csv_path.resolve())))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "la-bench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}