{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "33e6d903-c2af-4bb0-c189-f2cee098c564"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Google Colaboratoryç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ\n",
            "\n",
            "ğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\n",
            "âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\n",
            "\n",
            "ğŸ“¥ ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­: https://github.com/lasa-or-jp/la-bench.git\n",
            "âœ… ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å®Œäº†: la-bench/\n",
            "\n",
            "ğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: /content/la-bench/la-bench\n",
            "\n",
            "ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\n",
            "total 416\n",
            "drwxr-xr-x 8 root root   4096 Oct 21 08:33 .\n",
            "drwxr-xr-x 9 root root   4096 Oct 21 08:33 ..\n",
            "-rw-r--r-- 1 root root   4741 Oct 21 08:33 CLAUDE.md\n",
            "drwxr-xr-x 4 root root   4096 Oct 21 08:33 code\n",
            "-rw-r--r-- 1 root root   2658 Oct 21 08:33 CONTRIBUTING.md\n",
            "drwxr-xr-x 4 root root   4096 Oct 21 08:33 data\n",
            "drwxr-xr-x 3 root root   4096 Oct 21 08:33 docs\n",
            "drwxr-xr-x 8 root root   4096 Oct 21 08:33 .git\n",
            "drwxr-xr-x 3 root root   4096 Oct 21 08:33 .github\n",
            "-rw-r--r-- 1 root root    979 Oct 21 08:33 .gitignore\n",
            "-rw-r--r-- 1 root root   1101 Oct 21 08:33 LICENSE\n",
            "drwxr-xr-x 2 root root   4096 Oct 21 08:33 notebooks\n",
            "-rw-r--r-- 1 root root    569 Oct 21 08:33 pyproject.toml\n",
            "-rw-r--r-- 1 root root  12425 Oct 21 08:33 README.md\n",
            "-rw-r--r-- 1 root root    121 Oct 21 08:33 requirements.txt\n",
            "-rw-r--r-- 1 root root 346546 Oct 21 08:33 uv.lock\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: ç’°å¢ƒè¨­å®šã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "\"\"\"\n",
        "LA-Bench 2025: å®Ÿé¨“æ‰‹é †ç”Ÿæˆã‚¿ã‚¹ã‚¯\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— { display-mode: \"form\" }\n",
        "#@markdown ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Colabã‹ã©ã†ã‹ã®ç¢ºèª\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"âœ… Google Colaboratoryç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ\")\n",
        "    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "    print(\"\\nğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "    !pip install -q openai pyyaml tqdm pandas\n",
        "\n",
        "    print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
        "\n",
        "    # GitHubãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n",
        "    REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "    REPO_NAME = \"la-bench\"\n",
        "\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"\\nğŸ“¥ ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­: {REPO_URL}\")\n",
        "        !git clone -q {REPO_URL}\n",
        "        print(f\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å®Œäº†: {REPO_NAME}/\")\n",
        "    else:\n",
        "        print(f\"\\nğŸ“‚ ãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {REPO_NAME}/\")\n",
        "        print(\"ğŸ“¥ æœ€æ–°ç‰ˆã«æ›´æ–°ä¸­...\")\n",
        "        !cd {REPO_NAME} && git pull -q\n",
        "        print(\"âœ… æ›´æ–°å®Œäº†\")\n",
        "\n",
        "    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
        "    WORK_DIR = Path(REPO_NAME)\n",
        "    os.chdir(WORK_DIR)\n",
        "    print(f\"\\nğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n",
        "\n",
        "    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª\n",
        "    print(\"\\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\")\n",
        "    !ls -la\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­ã§ã™\")\n",
        "    if Path.cwd().name == \"notebooks\":\n",
        "        os.chdir(Path.cwd().parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PZr_6rXsyqlK",
        "outputId": "d0e409d7-815e-437d-936b-93c2f18cd844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”‘ OpenAI API Keyã‚’å…¥åŠ›: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ\n",
            "ğŸ”‘ APIã‚­ãƒ¼: ********************WTEA\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: OpenAI APIã‚­ãƒ¼ã®è¨­å®š\n",
        "#@title 2. OpenAI API Keyè¨­å®š { display-mode: \"form\" }\n",
        "#@markdown OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ã¯å®‰å…¨ã«ç®¡ç†ã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "\n",
        "# APIã‚­ãƒ¼ã®å–å¾—æ–¹æ³•ã‚’é¸æŠ\n",
        "use_secrets = False  #@param {type:\"boolean\"}\n",
        "#@markdown â˜ï¸ Google Colab Secretsã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯\n",
        "\n",
        "if IN_COLAB:\n",
        "    import getpass\n",
        "    from google.colab import userdata\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secretsã‹ã‚‰å–å¾—\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"âœ… APIã‚­ãƒ¼ã‚’Secretsã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ\")\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Secretsã‹ã‚‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "            print(\"å·¦å´ã®ãƒ‘ãƒãƒ«ã®ğŸ”‘ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰'OPENAI_API_KEY'ã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # ç›´æ¥å…¥åŠ›\n",
        "        api_key_input = getpass.getpass(\"ğŸ”‘ OpenAI API Keyã‚’å…¥åŠ›: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ‰‹æ³•ã®ã¿ä½¿ç”¨ï¼‰\")\n",
        "else:\n",
        "    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# APIã‚­ãƒ¼ã®æ¤œè¨¼\n",
        "if API_KEY:\n",
        "    print(f\"ğŸ”‘ APIã‚­ãƒ¼: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPTæ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "71dPwmdnzEfP",
        "outputId": "0bb3055c-0834-4568-ee80-2cadbdacee77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "å®Ÿè¡Œç’°å¢ƒ: Google Colab\n",
            "å®Ÿè¡Œæ™‚åˆ»: 2025-10-21 08:34:49\n",
            "OpenAIåˆ©ç”¨å¯èƒ½: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨è¨­å®š\n",
        "#@title 3. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Set, Any\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"âš ï¸ OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
        "\n",
        "# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ (Colabå¯¾å¿œ)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ãƒ­ã‚°è¨­å®š\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"å®Ÿè¡Œç’°å¢ƒ: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAIåˆ©ç”¨å¯èƒ½: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0rypmgB20Yc2"
      },
      "outputs": [],
      "source": [
        "# Cell 4: ãƒ‡ãƒ¼ã‚¿æ§‹é€ \n",
        "#@title 4. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ReferenceEntry:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ExampleInput:\n",
        "    instruction: str\n",
        "    mandatory_objects: Set[str] = field(default_factory=set)\n",
        "    source_protocol_steps: List[Step] = field(default_factory=list)\n",
        "    expected_final_states: Set[str] = field(default_factory=set)\n",
        "    references: List[ReferenceEntry] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ExampleOutput:\n",
        "    procedure_steps: List[Step] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class Measurement:\n",
        "    specific_criteria: Dict[str, int] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExampleSample:\n",
        "    id: str\n",
        "    input: ExampleInput\n",
        "    output: ExampleOutput\n",
        "    measurement: Optional[Measurement] = None\n",
        "\n",
        "def _to_set(x):\n",
        "    return set(x) if isinstance(x, (list, set, tuple)) else set()\n",
        "\n",
        "def _to_list(x):\n",
        "    return list(x) if isinstance(x, (list, set, tuple)) else (x if isinstance(x, list) else [])\n",
        "\n",
        "def _to_steps(x) -> List[Step]:\n",
        "    steps: List[Step] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return steps\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                sid = int(it.get(\"id\", len(steps) + 1))\n",
        "            except Exception:\n",
        "                sid = len(steps) + 1\n",
        "            steps.append(Step(id=sid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, s in enumerate(arr, start=1):\n",
        "            steps.append(Step(id=idx, text=str(s).strip()))\n",
        "    return steps\n",
        "\n",
        "def _to_references(x) -> List[ReferenceEntry]:\n",
        "    refs: List[ReferenceEntry] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return refs\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                rid = int(it.get(\"id\", len(refs) + 1))\n",
        "            except Exception:\n",
        "                rid = len(refs) + 1\n",
        "            refs.append(ReferenceEntry(id=rid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, ref in enumerate(arr, start=1):\n",
        "            refs.append(ReferenceEntry(id=idx, text=str(ref).strip()))\n",
        "    return refs\n",
        "\n",
        "def parse_sample(obj: Dict[str, Any]) -> ExampleSample:\n",
        "    sid = obj.get(\"id\") or obj.get(\"sample_id\") or \"unknown\"\n",
        "    i = obj.get(\"input\", {})\n",
        "    o = obj.get(\"output\", {})\n",
        "    m = obj.get(\"measurement\", {})\n",
        "\n",
        "    # Measurement.specific_criteria ã‚’ dict ã«æ­£è¦åŒ–ï¼ˆlistå½¢å¼ã‚‚è¨±å®¹ï¼‰\n",
        "    sc_raw = m.get(\"specific_criteria\", {})\n",
        "    sc: Dict[str, int] = {}\n",
        "    if isinstance(sc_raw, dict):\n",
        "        for k, v in sc_raw.items():\n",
        "            try:\n",
        "                sc[str(k)] = int(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "    elif isinstance(sc_raw, list):\n",
        "        for it in sc_raw:\n",
        "            try:\n",
        "                k = it.get(\"item\")\n",
        "                v = int(it.get(\"score\", 0))\n",
        "                if k:\n",
        "                    sc[str(k)] = v\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    sample = ExampleSample(\n",
        "        id=str(sid),\n",
        "        input=ExampleInput(\n",
        "            instruction=str(i.get(\"instruction\", \"\")).strip(),\n",
        "            mandatory_objects=_to_set(i.get(\"mandatory_objects\", [])),\n",
        "            source_protocol_steps=_to_steps(i.get(\"source_protocol_steps\", [])),\n",
        "            expected_final_states=_to_set(i.get(\"expected_final_states\", [])),\n",
        "            references=_to_references(i.get(\"references\", [])),\n",
        "        ),\n",
        "        output=ExampleOutput(\n",
        "            procedure_steps=_to_steps(o.get(\"procedure_steps\", []))\n",
        "        ),\n",
        "        measurement=Measurement(specific_criteria=sc) if sc else None\n",
        "    )\n",
        "    return sample\n",
        "\n",
        "def load_example_jsonl(path: str):\n",
        "    samples = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"JSONL not found: {p}\")\n",
        "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ JSONL parse error: {e}\")\n",
        "            continue\n",
        "        samples.append(parse_sample(obj))\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MXF0Ou0B6sFB",
        "outputId": "70e4b615-9237-4ee5-f44b-92707b8ecc9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded 5 samples from data/example/example.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: JSONLãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆ©ç”¨\n",
        "#@title 5. JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ { display-mode: \"form\" }\n",
        "#@markdown exampleã‚’ä½¿ã†ã¨ãï¼š`data/example/example.jsonl`\n",
        "#@markdown public_testã‚’ä½¿ã†ã¨ãï¼š`data/public_test/public_test.jsonl`\n",
        "\n",
        "jsonl_path = 'data/example/example.jsonl'  #@param {type:'string'}\n",
        "\n",
        "try:\n",
        "    samples = load_example_jsonl(jsonl_path)\n",
        "    print(f'âœ… Loaded {len(samples)} samples from {jsonl_path}')\n",
        "except Exception as e:\n",
        "    print(f'âŒ Load error: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WZ94EpzOInJr",
        "outputId": "fe2bbf99-5ff4-498f-cfc0-7dbf906e9bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ç”Ÿæˆå®Œäº†: 5 samples\n",
            "ä¾‹: sample_1 â†’ 11 steps\n",
            "ğŸ“„ Saved JSONL: outputs/runs/generated_20251021_083608.jsonl\n",
            "Download file: outputs/runs/generated_20251021_083608.jsonl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49901164-4f8b-4fad-b002-7e45b6127e0e\", \"generated_20251021_083608.jsonl\", 12968)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell 6: å®Ÿé¨“æ‰‹é †ã®ç”Ÿæˆï¼ˆOpenAI, Pydanticæ§‹é€ åŒ–ï¼‰\n",
        "#@title 6. LLMã§ Input ã‹ã‚‰ Outputï¼ˆprocedure_stepsï¼‰ã‚’ç”Ÿæˆ { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«è¨­å®š\n",
        "MODEL_NAME = \"gpt-4.1-mini-2025-04-14\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "#@markdown gpt-4o-mini, gpt-4o-2024-08-06, ã‚ã‚‹ã„ã¯ãã‚Œä»¥é™ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚<br>\n",
        "#@markdown (Structured outputã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚) <br>\n",
        "#@markdown gpt-5ç³»ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€temperature=1.0ã¨ã—ã¦ãã ã•ã„ã€‚\n",
        "TEMPERATURE = 0.7 # @param\n",
        "\n",
        "#@markdown `build_messages`é–¢æ•°ã«ãŠã„ã¦ã€LLMã®å…¥åŠ›ã‚’è¨­è¨ˆã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "class StepModel(BaseModel):\n",
        "    id: int = Field(ge=1, description=\"ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·\")\n",
        "    text: str = Field(description=\"å®Ÿé¨“æ‰‹é †ã®è©³ç´°ãªèª¬æ˜\")\n",
        "\n",
        "class GeneratedOutput(BaseModel):\n",
        "    procedure_steps: List[StepModel] = Field(\n",
        "        description=\"å®Ÿé¨“æ‰‹é †ã®ãƒªã‚¹ãƒˆ\",\n",
        "        min_items=1,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "def build_messages(sample: ExampleSample) -> list[dict]:\n",
        "    sys = (\n",
        "        \"ã‚ãªãŸã¯ç”Ÿå‘½ç§‘å­¦å®Ÿé¨“ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã® Input ã‚’èª­ã¿ã€\"\n",
        "        \"æ—¥æœ¬èªã§å®Ÿè¡Œå¯èƒ½ãªå®Ÿé¨“æ‰‹é †ï¼ˆprocedure_stepsï¼‰ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\"\n",
        "        \"åˆ¶ç´„: ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯æœ€å¤§50ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã¯10æ–‡ä»¥ä¸‹ã€idã¯1ã‹ã‚‰æ˜‡é †ã€‚\"\n",
        "    )\n",
        "    user_lines = []\n",
        "    user_lines.append(f\"ã€å®Ÿé¨“æŒ‡ç¤ºã€‘\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        user_lines.append(\"\\nã€ä½¿ç”¨ã™ã‚‹ç‰©å“ã€‘\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            user_lines.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        user_lines.append(\"\\nã€å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ‰‹é †ï¼ˆå‚è€ƒï¼‰ã€‘\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            user_lines.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        user_lines.append(\"\\nã€æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã€‘\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            user_lines.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        user_lines.append(\"\\nã€å‚è€ƒæ–‡çŒ®ã€‘\")\n",
        "        for ref in sample.input.references:\n",
        "            user_lines.append(f\"- [{ref.id}] {ref.text}\")\n",
        "    usr = \"\\n\".join(user_lines)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": usr},\n",
        "    ]\n",
        "\n",
        "def generate_outputs(samples: list[ExampleSample]) -> list[dict]:\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    results: list[dict] = []\n",
        "    for sm in samples:\n",
        "        msgs = build_messages(sm)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=MODEL_NAME,\n",
        "                messages=msgs,\n",
        "                temperature=TEMPERATURE,\n",
        "                response_format=GeneratedOutput,\n",
        "            )\n",
        "            parsed: GeneratedOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            steps = [\n",
        "                Step(id=s.id, text=s.text)\n",
        "                for s in sorted(parsed.procedure_steps, key=lambda x: x.id)\n",
        "            ][:50]\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç”Ÿæˆå¤±æ•—: {sm.id}: {e}\")\n",
        "            steps = []  # no fallback\n",
        "        results.append({\n",
        "            \"id\": sm.id,\n",
        "            \"procedure_steps\": [{\"id\": s.id, \"text\": s.text} for s in steps],\n",
        "        })\n",
        "    print(f\"âœ… ç”Ÿæˆå®Œäº†: {len(results)} samples\")\n",
        "    return results\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "generated_results = generate_outputs(samples)\n",
        "if generated_results:\n",
        "    print(f\"ä¾‹: {generated_results[0]['id']} â†’ {len(generated_results[0]['procedure_steps'])} steps\")\n",
        "\n",
        "# ç”Ÿæˆçµæœã‚’ JSONL ã§ä¿å­˜ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "out_dir = Path('./outputs/runs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "jsonl_path = out_dir / f'generated_{ts}.jsonl'\n",
        "with jsonl_path.open('w', encoding='utf-8') as f:\n",
        "    for rec in generated_results:\n",
        "        obj = {\"id\": rec[\"id\"], \"output\": {\"procedure_steps\": rec[\"procedure_steps\"]}}\n",
        "        line = json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"ğŸ“„ Saved JSONL: {jsonl_path}\")\n",
        "\n",
        "# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆColab/ãƒ­ãƒ¼ã‚«ãƒ«åŒæ–¹ã«å¯¾å¿œï¼‰\n",
        "try:\n",
        "    from google.colab import files as colab_files  # type: ignore\n",
        "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’å‡ºã—ã¦ã€yãªã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "    from google.colab.output import eval_js\n",
        "    print(f\"Download file: {jsonl_path}\")\n",
        "    confirm = eval_js('confirm(\"ç”Ÿæˆã•ã‚ŒãŸJSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(jsonl_path))\n",
        "    else:\n",
        "      print(\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "except Exception:\n",
        "    from IPython.display import FileLink, display\n",
        "    display(FileLink(str(jsonl_path.resolve())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wYtMf3bJOzcN",
        "outputId": "571c0af2-c127-470c-f479-a01a6bf5b612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LLM-as-a-judge: Scored 5 samples (0-10)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         id  general_score  specific_score  total_score\n",
              "0  sample_1            5.0             3.0          8.0\n",
              "1  sample_2            5.0             3.0          8.0\n",
              "2  sample_3            5.0             3.0          8.0\n",
              "3  sample_4            5.0             2.0          7.0\n",
              "4  sample_5            5.0             3.0          8.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>general_score</th>\n",
              "      <th>specific_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sample_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ad59dd2e-ed1f-496f-b18f-2a6fbce1318f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4743e574-c900-4522-9fc4-87cd325857b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4743e574-c900-4522-9fc4-87cd325857b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4743e574-c900-4522-9fc4-87cd325857b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(FileLink(str(csv_path\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"sample_2\",\n          \"sample_5\",\n          \"sample_3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specific_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 2.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4472135954999579,\n        \"min\": 7.0,\n        \"max\": 8.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Saved: outputs/runs/eval_llm_20251021_083608.csv\n",
            "Download file: outputs/runs/eval_llm_20251021_083608.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0950a69f-f73b-451a-862a-12c36180c242\", \"eval_llm_20251021_083608.csv\", 1204)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Cell 7: LLM-as-a-judge è©•ä¾¡ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰\n",
        "#@title 7. LLM ã§å…±é€š5ç‚¹ + å€‹åˆ¥5ç‚¹ã‚’æ¡ç‚¹ { display-mode: \"form\" }\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"OpenAI SDK v1 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`uv add openai` ã§è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\") from e\n",
        "\n",
        "JUDGE_MODEL = \"gpt-4.1-mini\"  # é«˜æ€§èƒ½æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´å¯\n",
        "JUDGE_TEMPERATURE = 0.2\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    general_score: float = Field(ge=0, le=5)\n",
        "    specific_score: float = Field(ge=0, le=5)\n",
        "    final_score: float = Field(ge=0, le=10)\n",
        "    general_reason: str\n",
        "    specific_matches: List[str] = []\n",
        "    notes: Optional[str] = None\n",
        "\n",
        "def build_judge_messages(sample: ExampleSample, steps: List[Step]) -> list[dict]:\n",
        "    # è©•ä¾¡åŸºæº–ï¼ˆå…±é€š5ç‚¹ + å€‹åˆ¥5ç‚¹ï¼‰\n",
        "    system = (\n",
        "        \"ã‚ãªãŸã¯ç”Ÿå‘½ç§‘å­¦å®Ÿé¨“ã®å°‚é–€å®¶ã§ã‚ã‚Šã€å…¬å¹³ãªæ¡ç‚¹è€…ã§ã™ã€‚\"\n",
        "        \"ä»¥ä¸‹ã®åŸºæº–ã«å¾“ã£ã¦ã€ä¸ãˆã‚‰ã‚ŒãŸ Input ã¨ç”Ÿæˆæ‰‹é †ï¼ˆOutputï¼‰ã‚’è©•ä¾¡ã—ã€\"\n",
        "        \"general_score(0-5) ã¨ specific_score(0-5) ã¨ final_score(0-10) ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\"\n",
        "        \"\\n\\n[å…±é€šæ¡ç‚¹åŸºæº– 5ç‚¹æº€ç‚¹]\\n\"\n",
        "        \"åŠ ç‚¹(+1ãšã¤): 1) å®Ÿé¨“æŒ‡ç¤ºã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åæ˜ , 2) ä½¿ç”¨ã™ã‚‹ç‰©å“ã®åæ˜ , 3) å…ƒæ‰‹é †ã®è«–ç†åæ˜ , 4) æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã®é”æˆ, 5) é©åˆ‡ãªè£œå®Œã€‚\\n\"\n",
        "        \"æ¸›ç‚¹: ä¸è‡ªç„¶ãªæ—¥æœ¬èª/ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³, è¨ˆç®—ãƒŸã‚¹, æ‰‹é †çŸ›ç›¾ã€‚\\n\"\n",
        "        \"ä¸Šé™: å…¥åŠ›æ‰‹é †ã®ä¸¸å†™ã—ç­‰ã®éåº¦ã®å®‰å…¨æ€§ãŒè¦‹ã‚‰ã‚Œã‚‹å ´åˆã€general_score ã¯æœ€å¤§2ç‚¹ã«åˆ¶é™ã€‚\\n\\n\"\n",
        "        \"[å€‹åˆ¥æ¡ç‚¹åŸºæº– 5ç‚¹æº€ç‚¹]\\n\"\n",
        "        \"ä¸ãˆã‚‰ã‚ŒãŸ specific_criteria ã®å„ item ãŒæ‰‹é †ã«å«ã¾ã‚Œã‚‹/æº€ãŸã™ãªã‚‰ã€ãã® score ã‚’åŠ ç‚¹ï¼ˆåˆè¨ˆ5ç‚¹ã§ä¸Šé™ï¼‰ã€‚\"\n",
        "    )\n",
        "\n",
        "    parts = []\n",
        "    parts.append(f\"ã€å®Ÿé¨“æŒ‡ç¤ºã€‘\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        parts.append(\"\\nã€ä½¿ç”¨ã™ã‚‹ç‰©å“ã€‘\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            parts.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        parts.append(\"\\nã€å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ‰‹é †ï¼ˆå‚è€ƒï¼‰ã€‘\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            parts.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        parts.append(\"\\nã€æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã€‘\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            parts.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        parts.append(\"\\nã€å‚è€ƒæ–‡çŒ®ã€‘\")\n",
        "        for ref in sample.input.references:\n",
        "            parts.append(f\"- [{ref.id}] {ref.text}\")\n",
        "\n",
        "    parts.append(\"\\nã€ç”Ÿæˆæ‰‹é †ï¼ˆOutputï¼‰ã€‘\")\n",
        "    for s in steps:\n",
        "        parts.append(f\"- {s.id}. {s.text}\")\n",
        "\n",
        "    parts.append(\"\\nã€specific_criteriaã€‘\")\n",
        "    if sample.measurement and sample.measurement.specific_criteria:\n",
        "        for item, sc in sample.measurement.specific_criteria.items():\n",
        "            parts.append(f\"- ({int(sc)}ç‚¹) {item}\")\n",
        "    else:\n",
        "        parts.append(\"- ãªã—\")\n",
        "\n",
        "    user = \"\\n\".join(parts)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "def judge_with_llm(samples: List[ExampleSample], generated: list[dict]) -> pd.DataFrame:\n",
        "    client = OpenAI(api_key=API_KEY) if 'API_KEY' in globals() and API_KEY else OpenAI()\n",
        "    proc_map = {g['id']: [Step(id=it['id'], text=it['text']) for it in g['procedure_steps']] for g in generated}\n",
        "    rows = []\n",
        "    quota_exhausted = False\n",
        "    def _is_insufficient_quota(err: Exception) -> bool:\n",
        "        s = str(err)\n",
        "        return 'insufficient_quota' in s or 'You exceeded your current quota' in s\n",
        "    for sm in samples:\n",
        "        if quota_exhausted:\n",
        "            print(f\"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—æ¡ç‚¹: {sm.id}ï¼ˆã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ï¼‰\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_due_to_quota',\n",
        "            })\n",
        "            continue\n",
        "        steps = proc_map.get(sm.id, [])\n",
        "        msgs = build_judge_messages(sm, steps)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=msgs,\n",
        "                temperature=JUDGE_TEMPERATURE,\n",
        "                response_format=JudgeOutput,\n",
        "            )\n",
        "            parsed: JudgeOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': parsed.general_score,\n",
        "                'specific_score': parsed.specific_score,\n",
        "                'total_score': parsed.final_score,\n",
        "                'notes': parsed.notes or '',\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è©•ä¾¡å¤±æ•—: {sm.id}: {e}\")\n",
        "            if _is_insufficient_quota(e):\n",
        "                print(\"âš ï¸ APIã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã€ä»¥é™ã®æ¡ç‚¹ã‚’ä¸­æ–­ã—ã¾ã™ã€‚ãƒ—ãƒ©ãƒ³/èª²é‡‘è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚\")\n",
        "                quota_exhausted = True\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'evaluation_failed',\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "df = judge_with_llm(samples, generated_results)\n",
        "print(f\"âœ… LLM-as-a-judge: Scored {len(df)} samples (0-10)\")\n",
        "try:\n",
        "    display(df[['id','general_score','specific_score','total_score']])\n",
        "except Exception:\n",
        "    print(df[['id','general_score','specific_score','total_score']])\n",
        "\n",
        "csv_path = out_dir / f'eval_llm_{ts}.csv'\n",
        "df.to_csv(csv_path, index=False, encoding=\"utf_8_sig\")\n",
        "print(f'ğŸ“„ Saved: {csv_path}')\n",
        "\n",
        "try:\n",
        "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’å‡ºã—ã¦ã€yãªã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "    print(f\"Download file: {csv_path}\")\n",
        "    confirm = eval_js('confirm(\"ç”Ÿæˆã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(csv_path))\n",
        "    else:\n",
        "      print(\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "except Exception:\n",
        "    display(FileLink(str(csv_path.resolve())))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "la-bench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}